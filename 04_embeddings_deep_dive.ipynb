{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personality and It's Transformations ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An analysis of prof. Jordan Peterson's collection of lectures from University of Toronto personality course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lectures in video form provided at: https://www.youtube.com/playlist?list=PL22J3VaeABQAOhH1CLMNnMl2R-O1abW1T     |    More about prof. Peterson at https://www.jordanbpeterson.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from constants import *\n",
    "\n",
    "import umap\n",
    "import hdbscan\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nltk\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"tomcolor8\">  \n",
    "<h4 style=\"background:#135e96; color:white ;font-size:15px;line-height:1em; text-align:left; padding: 20px\">\n",
    "      Load the data</h4> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{OUTPUT_FOLDER}\\{FINAL_CAPTIONS_FILE_NAME}', 'r', encoding='utf-8') as f:\n",
    "    data = f.readlines()\n",
    "data = [sent.replace('\\n', '') for sent in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Well, after all that.',\n",
       " 'So, welcome to Psychology 230.',\n",
       " 'Nice to see you all here.',\n",
       " 'So, what I’m going to do today—how I’m going to start—is I’m going to give you an overview of the content of the course',\n",
       " 'and then I’ll give you an overview of the class requirements right at the end.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"tomcolor8\">  \n",
    "<h4 style=\"background:#135e96; color:white ;font-size:15px;line-height:1em; text-align:left; padding: 20px\">\n",
    "      Check the dataset</h4> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6144"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NO_OF_SENTS = len(data)\n",
    "NO_OF_SENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 6144 sentences in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "LONGEST_SENTENCE = 315"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maximal number of words in a single sentence is 315 (information obtained from notebook 02). This is because oral lectures typically are chains of thoughts from the speaker and don't follow a syntactic structure typical for written information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"tomcolor8\">  \n",
    "<h4 style=\"background:#135e96; color:white ;font-size:15px;line-height:1em; text-align:left; padding: 20px\">\n",
    "      Model implementation</h4> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A paraphrase identification model was chosen because generally models like those are good at similarity and retrieval tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 391/391 [00:00<00:00, 78.2kB/s]\n",
      "Downloading: 100%|██████████| 190/190 [00:00<00:00, 61.4kB/s]\n",
      "Downloading: 100%|██████████| 3.74k/3.74k [00:00<00:00, 1.88MB/s]\n",
      "Downloading: 100%|██████████| 718/718 [00:00<00:00, 240kB/s]\n",
      "Downloading: 100%|██████████| 122/122 [00:00<00:00, 60.9kB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 464kB/s]  \n",
      "Downloading: 100%|██████████| 229/229 [00:00<00:00, 85.3kB/s]\n",
      "Downloading: 100%|██████████| 329M/329M [01:16<00:00, 4.30MB/s] \n",
      "Downloading: 100%|██████████| 53.0/53.0 [00:00<00:00, 26.5kB/s]\n",
      "Downloading: 100%|██████████| 239/239 [00:00<00:00, 108kB/s]\n",
      "Downloading: 100%|██████████| 1.36M/1.36M [00:01<00:00, 719kB/s]\n",
      "Downloading: 100%|██████████| 1.35k/1.35k [00:00<00:00, 448kB/s]\n",
      "Downloading: 100%|██████████| 798k/798k [00:01<00:00, 640kB/s]  \n"
     ]
    }
   ],
   "source": [
    "model_name = 'paraphrase-distilroberta-base-v1'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chooses model is a STS model that was trained on NLI Data and fine-tuned on a STS benchmark dataset. This means that the model is suitable for semantic similarity cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.max_seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default model has length 128, but it must be increased because our longest sentence has 315 words and the number of tokens will be even greater. A max value of 512 will be set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.max_seq_length = SENT_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: RobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This  model uses a mean pooling layer. Mean-pooling approach has the highest performences on NLI and STSb datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the model is a Roberta-based model which ensures better results over models like Bert and XLNet on  GLUE benchmatk since Roberta was trained on a larger dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"tomcolor8\">  \n",
    "<h4 style=\"background:#135e96; color:white ;font-size:15px;line-height:1em; text-align:left; padding: 20px\">\n",
    "      Make basic embeddings</h4> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 48/48 [04:32<00:00,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "embeddings = model.encode(data, batch_size=128, convert_to_numpy=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6144, 768) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.0123798 ,  0.2777767 , -0.01405326, ..., -0.02678889,\n",
       "         0.0440481 ,  0.07773362],\n",
       "       [ 0.0412908 ,  0.16136691,  0.02991316, ...,  0.58379775,\n",
       "         0.14942285,  0.06346925],\n",
       "       [-0.07501768,  0.4233095 , -0.0145098 , ...,  0.3354782 ,\n",
       "         0.41762507, -0.00107434],\n",
       "       ...,\n",
       "       [ 0.00656715,  0.14959471,  0.0819371 , ...,  0.1627527 ,\n",
       "         0.10600454,  0.02682198],\n",
       "       [ 0.40873355, -0.28501305,  1.0132747 , ...,  0.09641482,\n",
       "         0.09259903, -0.08356792],\n",
       "       [ 0.40873355, -0.28501305,  1.0132747 , ...,  0.09641482,\n",
       "         0.09259903, -0.08356792]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embeddings.shape, type(embeddings))\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{MODELS_FOLDER}\\{model_name}.npy', 'wb') as f:\n",
    "    np.save(f, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'{MODELS_FOLDER}\\{SAMPLE_EMBEDDINGS_MODEL_NAME}.npy', 'rb') as f:\n",
    "#     embeddings = np.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"tomcolor8\">  \n",
    "<h4 style=\"background:#135e96; color:white ;font-size:15px;line-height:1em; text-align:left; padding: 20px\">\n",
    "      Dimensionality reduction</h4> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***UMAP*** for a dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = 20\n",
    "components = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`n_neighbors` regulates whether UMAP should focus more on global or lobal scructures of the data. Low values of n_neighbors will force UMAP to concentrate on very local structure (it will find patterns in local small sections not seeing the big picture), while large values will push UMAP to look at larger neighborhoods (focusing on the big picture) losing fine distinct features of local, smaller neighborhoods. You can think of this like literally focusing on your neighbors when you live for example on a country side. If n_neighbors is small someone can describe you  based on your membership to only your small community (e.g. people from your street). If n_neighbors is large someone can describe you based on the judgement from people from the whole city or state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`n_components` the dimensionality of the reduced dimension space we will be embedding the data into."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be trying to reduce 768 dimmentions to 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the sample model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP(angular_rp_forest=True, learning_rate=0.4, metric='cosine', min_dist=0.0, n_components=10, n_epochs=4000, n_neighbors=20, verbose=True)\n",
      "Sun Mar 26 16:43:17 2023 Construct fuzzy simplicial set\n",
      "Sun Mar 26 16:43:17 2023 Finding Nearest Neighbors\n",
      "Sun Mar 26 16:43:17 2023 Building RP forest with 9 trees\n",
      "Sun Mar 26 16:43:19 2023 NN descent for 13 iterations\n",
      "\t 1  /  13\n",
      "\t 2  /  13\n",
      "\t 3  /  13\n",
      "\t 4  /  13\n",
      "\t 5  /  13\n",
      "\t 6  /  13\n",
      "\tStopping threshold met -- exiting after 6 iterations\n",
      "Sun Mar 26 16:43:42 2023 Finished Nearest Neighbor Search\n",
      "Sun Mar 26 16:43:46 2023 Construct embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs completed: 100%| ██████████ 4000/4000 [01:25]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar 26 16:45:11 2023 Finished embedding\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "umap_embeddings = umap.UMAP(\n",
    "    n_neighbors = neighbors,\n",
    "    n_components = components,\n",
    "    n_epochs = 4000,\n",
    "    min_dist = 0.0,\n",
    "    learning_rate = 0.4,\n",
    "    verbose = True,\n",
    "    metric = 'cosine').fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6144, 10) <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4.117645 , -2.6297238, -5.509396 , ...,  3.990224 ,  1.3424809,\n",
       "         6.777611 ],\n",
       "       [ 4.4338374, -2.780574 , -5.4009767, ...,  4.1286774,  1.75264  ,\n",
       "         6.7089186],\n",
       "       [ 4.403378 , -2.7203526, -5.3707123, ...,  4.151954 ,  1.6832632,\n",
       "         6.72946  ],\n",
       "       ...,\n",
       "       [ 3.590335 , -2.251292 , -5.4956255, ...,  3.858005 ,  0.909016 ,\n",
       "         7.127821 ],\n",
       "       [ 6.8634176, -4.69741  , -4.831684 , ...,  4.135488 ,  4.3332205,\n",
       "         5.906978 ],\n",
       "       [ 6.8615193, -4.6955276, -4.833147 , ...,  4.1339765,  4.331313 ,\n",
       "         5.9084005]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(umap_embeddings.shape, type(umap_embeddings))\n",
    "umap_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"tomcolor8\">  \n",
    "<h4 style=\"background:#135e96; color:white ;font-size:15px;line-height:1em; text-align:left; padding: 20px\">\n",
    "      Clustering</h4> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***HDBSCAN*** is a hierarchical clustering algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'euclidean': hdbscan.dist_metrics.EuclideanDistance,\n",
       " 'l2': hdbscan.dist_metrics.EuclideanDistance,\n",
       " 'minkowski': hdbscan.dist_metrics.MinkowskiDistance,\n",
       " 'p': hdbscan.dist_metrics.MinkowskiDistance,\n",
       " 'manhattan': hdbscan.dist_metrics.ManhattanDistance,\n",
       " 'cityblock': hdbscan.dist_metrics.ManhattanDistance,\n",
       " 'l1': hdbscan.dist_metrics.ManhattanDistance,\n",
       " 'chebyshev': hdbscan.dist_metrics.ChebyshevDistance,\n",
       " 'infinity': hdbscan.dist_metrics.ChebyshevDistance,\n",
       " 'seuclidean': hdbscan.dist_metrics.SEuclideanDistance,\n",
       " 'mahalanobis': hdbscan.dist_metrics.MahalanobisDistance,\n",
       " 'wminkowski': hdbscan.dist_metrics.WMinkowskiDistance,\n",
       " 'hamming': hdbscan.dist_metrics.HammingDistance,\n",
       " 'canberra': hdbscan.dist_metrics.CanberraDistance,\n",
       " 'braycurtis': hdbscan.dist_metrics.BrayCurtisDistance,\n",
       " 'matching': hdbscan.dist_metrics.MatchingDistance,\n",
       " 'jaccard': hdbscan.dist_metrics.JaccardDistance,\n",
       " 'dice': hdbscan.dist_metrics.DiceDistance,\n",
       " 'kulsinski': hdbscan.dist_metrics.KulsinskiDistance,\n",
       " 'rogerstanimoto': hdbscan.dist_metrics.RogersTanimotoDistance,\n",
       " 'russellrao': hdbscan.dist_metrics.RussellRaoDistance,\n",
       " 'sokalmichener': hdbscan.dist_metrics.SokalMichenerDistance,\n",
       " 'sokalsneath': hdbscan.dist_metrics.SokalSneathDistance,\n",
       " 'haversine': hdbscan.dist_metrics.HaversineDistance,\n",
       " 'cosine': hdbscan.dist_metrics.ArccosDistance,\n",
       " 'arccos': hdbscan.dist_metrics.ArccosDistance,\n",
       " 'pyfunc': hdbscan.dist_metrics.PyFuncDistance}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdbscan.dist_metrics.METRIC_MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cluser_size = 80\n",
    "min_samples = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`min_cluster_size` - the minimum size a final cluster can be.   \n",
    "`min_samples` - the higher this is, the more points are going to be treeted as outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 380 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clusters = hdbscan.HDBSCAN(\n",
    "    min_cluster_size = min_cluser_size,\n",
    "    metric = 'euclidean',\n",
    "    min_samples = min_samples,\n",
    "    cluster_selection_epsilon = 0.1,\n",
    "    cluster_selection_method = 'leaf',\n",
    "    leaf_size = 35,\n",
    "    algorithm = 'best').fit(umap_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_statistics(clusters:hdbscan.hdbscan_.HDBSCAN, \n",
    "compact : bool = False) -> pd.DataFrame:\n",
    "    \"\"\"Print basic statistic about a given structure of clusters\n",
    "        - number of unique clusters\n",
    "        - number of all points\n",
    "        - number of points treeted as outliers (noise)\n",
    "        This also plots distribution of the clusters\n",
    "\n",
    "    Args:\n",
    "        clusters (hdbscan.hdbscan_.HDBSCAN): HDBSCAN clusters \n",
    "        compact (bool): if True only two values (number of clusters and \n",
    "        percentage of noise) will be outputed\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: a dataframe with basic statistics\n",
    "        Additionaly a plot of cluster distribution in shown.\n",
    "    \"\"\"\n",
    "\n",
    "    # empty dataframe\n",
    "    summary = pd.DataFrame(columns = ['metric', 'value'])\n",
    "    summary.at[0, 'metric'] = 'Number of unique clusters'\n",
    "\n",
    "    # get number of all clusters in first row\n",
    "    summary.at[0, 'value'] = len(set(clusters.labels_))\n",
    "\n",
    "    # count number of points in each cluster (sentences in each group)\n",
    "    cnt = Counter()\n",
    "    cnt.update(clusters.labels_)\n",
    "\n",
    "    # total number of all sentences\n",
    "    sum_of_all_elements = sum([entry[1] for entry in cnt.most_common()])\n",
    "    # number of outlier sentences\n",
    "    sum_of_empty_elements = [entry[1] for entry in cnt.most_common() if entry[0] == -1][0]\n",
    "\n",
    "    # get total number of all sentences and number of outliers into the dataframe\n",
    "    summary.at[1, 'metric'] = 'Number of all sentences'\n",
    "    summary.at[1, 'value'] = sum_of_all_elements\n",
    "    \n",
    "    summary.at[2, 'metric'] = 'Number of noise'\n",
    "\n",
    "    # calculate how many percent of total sentences are the outlier sentences\n",
    "    percentage = '{:.4}'.format(str((sum_of_empty_elements/sum_of_all_elements)*100))\n",
    "    summary.at[2, 'value'] = f'{sum_of_empty_elements} ({percentage}%)'\n",
    "\n",
    "    # get points for the distribution showing number of sentences in each cluster\n",
    "    x, y= zip(*cnt.most_common())\n",
    "\n",
    "    # output plot and dataframe as summay\n",
    "    if compact != True:\n",
    "        plt.bar(x, y);\n",
    "        return summary\n",
    "\n",
    "    # output only number of clusters and percentage of noise\n",
    "    else:\n",
    "        return len(set(clusters.labels_)), sum_of_empty_elements/sum_of_all_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Number of unique clusters</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Number of all sentences</td>\n",
       "      <td>6144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Number of noise</td>\n",
       "      <td>2425 (39.4%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      metric         value\n",
       "0  Number of unique clusters            24\n",
       "1    Number of all sentences          6144\n",
       "2            Number of noise  2425 (39.4%)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster_statistics(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"tomcolor8\">  \n",
    "<h4 style=\"background:#135e96; color:white ;font-size:15px;line-height:1em; text-align:left; padding: 20px\">\n",
    "      Cluster analysis</h4> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.DataFrame(data, columns=['text'])\n",
    "final_data['cluster_ids'] = clusters.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cluster_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, after all that.</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So, welcome to Psychology 230.</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nice to see you all here.</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So, what I’m going to do today—how I’m going t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and then I’ll give you an overview of the clas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6139</th>\n",
       "      <td>And if you're on the low end of the IQ distrib...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6140</th>\n",
       "      <td>It has nothing to do with willingness to work,...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6141</th>\n",
       "      <td>And it's a good thing to know, even though it'...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6142</th>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6143</th>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6144 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  cluster_ids\n",
       "0                                 Well, after all that.           18\n",
       "1                        So, welcome to Psychology 230.           15\n",
       "2                             Nice to see you all here.           15\n",
       "3     So, what I’m going to do today—how I’m going t...            1\n",
       "4     and then I’ll give you an overview of the clas...            1\n",
       "...                                                 ...          ...\n",
       "6139  And if you're on the low end of the IQ distrib...            6\n",
       "6140  It has nothing to do with willingness to work,...           -1\n",
       "6141  And it's a good thing to know, even though it'...           21\n",
       "6142                                                              -1\n",
       "6143                                                              -1\n",
       "\n",
       "[6144 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_ids</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>So, there’s a website—I don’t really like Blac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>So when we’re first born—we’re very primitive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>So, what I’m going to do today—how I’m going t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>So the first issue is that there’s a lot of re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>But I think we might as well jump right into t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>You know, imagine a well-behaved four-year-old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Well, first, your parents take care of you so ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>You know and that requires a fair bit of intel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>First of all, obviously all the words you use ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>That’s a reasonable way of thinking about it, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>Most of the brain is structured with the olfac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>It brings in elements of cultural history, ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>Now, part of the reason for that is that Nietz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>You don’t really have to learn what anger mean...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>And useful, like there’s a difference between ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>So that the fact that you know them makes a di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>So, welcome to Psychology 230. Nice to see you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>But they like things cut and dried and laid ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>You think in terms of the presence of positive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>Well, after all that. And, so, some people wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>So what I would say is that, you know, Freud’s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>So, personality is a somewhat peculiar field o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "      <td>You know, you’re really really really really c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>but it’s not; that’s what the data indicate. a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cluster_ids                                               text\n",
       "0            -1  So, there’s a website—I don’t really like Blac...\n",
       "1             0  So when we’re first born—we’re very primitive ...\n",
       "2             1  So, what I’m going to do today—how I’m going t...\n",
       "3             2  So the first issue is that there’s a lot of re...\n",
       "4             3  But I think we might as well jump right into t...\n",
       "5             4  You know, imagine a well-behaved four-year-old...\n",
       "6             5  Well, first, your parents take care of you so ...\n",
       "7             6  You know and that requires a fair bit of intel...\n",
       "8             7  First of all, obviously all the words you use ...\n",
       "9             8  That’s a reasonable way of thinking about it, ...\n",
       "10            9  Most of the brain is structured with the olfac...\n",
       "11           10  It brings in elements of cultural history, ele...\n",
       "12           11  Now, part of the reason for that is that Nietz...\n",
       "13           12  You don’t really have to learn what anger mean...\n",
       "14           13  And useful, like there’s a difference between ...\n",
       "15           14  So that the fact that you know them makes a di...\n",
       "16           15  So, welcome to Psychology 230. Nice to see you...\n",
       "17           16  But they like things cut and dried and laid ou...\n",
       "18           17  You think in terms of the presence of positive...\n",
       "19           18  Well, after all that. And, so, some people wil...\n",
       "20           19  So what I would say is that, you know, Freud’s...\n",
       "21           20  So, personality is a somewhat peculiar field o...\n",
       "22           21  You know, you’re really really really really c...\n",
       "23           22  but it’s not; that’s what the data indicate. a..."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = final_data.groupby(['cluster_ids'], as_index=False).agg({'text': ' '.join})\n",
    "emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"tomcolor8\">  \n",
    "<h4 style=\"background:#135e96; color:white ;font-size:15px;line-height:1em; text-align:left; padding: 20px\">\n",
    "      Visualisation</h4> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data needs to be reduced to 3 dimmentions for visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "umap_3d = umap.UMAP(\n",
    "    n_neighbors = neighbors,\n",
    "    n_components = 3,\n",
    "    min_dist = 0.5,\n",
    "    n_epochs = 8000,\n",
    "    learning_rate = 0.4,\n",
    "    metric = 'cosine').fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show all reduced representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-28.714792, -15.19382 ,  18.921694],\n",
       "       [-28.397114, -16.017143,  18.982752],\n",
       "       [-28.356453, -15.314465,  18.82739 ],\n",
       "       ...,\n",
       "       [-28.663343, -14.922752,  20.676317],\n",
       "       [-26.273556, -15.849585,  17.226255],\n",
       "       [-26.381483, -15.794907,  17.190437]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umap_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 15, 15, 1, 1]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_list = list(clusters.labels_)\n",
    "cluster_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(2,3), stop_words='english')\n",
    "tf_idf = vectorizer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "words = vectorizer.get_feature_names()\n",
    "\n",
    "tf_idf_trans = tf_idf.T.toarray()\n",
    "tf_idf_trans.argsort()[:, -n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = tf_idf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f5dc7221bd57f443bd21d92d893b3958d3081f94c6c945d5f95188cb4cde5b4f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
